{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: kernel kernelspec migrate run script troubleshoot\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import imageio\n",
    "import diffusers\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, fixed\n",
    "from IPython.display import Image, display, clear_output\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from diffusers import (\n",
    "    DiffusionPipeline,\n",
    "    StableDiffusionPipeline,\n",
    "    EulerDiscreteScheduler,\n",
    "    PNDMScheduler,\n",
    "    LMSDiscreteScheduler,\n",
    ")\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Manually enabling the ipywidgets\n",
    "# (in case the widgets still do not get displayed correctly, have a look at https://ipywidgets.readthedocs.io/en/latest/user_install.html)\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(prompt, num_images, scheduler, steps):\n",
    "    pipeline = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "    # Load the LoRA weights for the model\n",
    "    pipeline.load_lora_weights(\"Checkpoint_L1/checkpoint-250\", weight_name=\"pytorch_lora_weights.safetensors\")\n",
    "\n",
    "    # Set the scheduler (this part is a placeholder, please adapt to your needs)\n",
    "    if scheduler == \"DDIM\":\n",
    "        pipeline = AutoPipelineForText2Image.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "    # Add other schedulers as needed\n",
    "\n",
    "    # Generate images based on the prompt\n",
    "    images = []\n",
    "    for _ in range(num_images):\n",
    "        image = pipeline(prompt, num_inference_steps=steps, guidance_scale=7.5).images[0]\n",
    "        images.append(image)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe05549f2f2482598dc50e697aec990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='', description='Prompt:', placeholder='Enter your prompt...'), IntSliderâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_images(prompt, num_images, steps, scheduler):\n",
    "    images = generate_images(prompt, num_images, scheduler, steps)\n",
    "    for idx, img in enumerate(images):\n",
    "        display(img)\n",
    "        img.save(f\"generated_image_{idx+1}.png\")\n",
    "\n",
    "# Create interactive widgets\n",
    "interactive_plot = interactive(display_images,\n",
    "                               prompt=widgets.Textarea(value='', placeholder='Enter your prompt...', description='Prompt:'),\n",
    "                               num_images=widgets.IntSlider(value=1, min=1, max=10, step=1, description='Num Images:'),\n",
    "                               steps=widgets.IntSlider(value=50, min=1, max=100, step=1, description='Inference Steps:'),\n",
    "                               scheduler=widgets.Dropdown(options=[\"DDIM\", \"PLMS\", \"Euler\", \"Euler a\", \"LMS\", \"Heun\", \"DPM2\", \"DPM2 a\", \"DPM++\", \"DPM++ a\"], value='DDIM', description='Scheduler:'))\n",
    "\n",
    "# Display the interactive widgets\n",
    "display(interactive_plot)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bachelor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
