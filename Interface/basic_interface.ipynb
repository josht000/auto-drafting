{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floor Plan Generator\n",
    "\n",
    "This notebook provides an interface to generate floor plans. You can input a text prompt, choose the number of images to generate, select the inference steps, and pick the scheduler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Istall required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch diffusers ipywidgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: kernel kernelspec migrate run script troubleshoot\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import imageio\n",
    "import diffusers\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, fixed\n",
    "from IPython.display import Image, display, clear_output\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from diffusers import (\n",
    "    DiffusionPipeline,\n",
    "    StableDiffusionPipeline,\n",
    "    EulerDiscreteScheduler,\n",
    "    PNDMScheduler,\n",
    "    LMSDiscreteScheduler)\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image generation funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(prompt, num_images, scheduler, steps):\n",
    "    pipeline = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "    # Load the LoRA weights for the model\n",
    "    pipeline.load_lora_weights(\"Checkpoint_L1/checkpoint-250\", weight_name=\"pytorch_lora_weights.safetensors\")\n",
    "\n",
    "    # Set the scheduler (this part is a placeholder, please adapt to your needs)\n",
    "    if scheduler == \"DDIM\":\n",
    "        pipeline.scheduler = DDIMScheduler.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"scheduler\")\n",
    "    # Add other schedulers as needed\n",
    "\n",
    "    # Generate images based on the prompt\n",
    "    images = []\n",
    "    for _ in range(num_images):\n",
    "        image = pipeline(prompt, num_inference_steps=steps, guidance_scale=7.5).images[0]\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Use cuda if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_model = DiffusionPipeline()\n",
    "\n",
    "\n",
    "def load_model(model_name: str, device: str = DEVICE):\n",
    "    \"\"\"Function that loads a pretrained model from the HuggingFace model hub and moves it to the specified device\n",
    "\n",
    "    Arguments:\n",
    "        model_name (str): Name of the model to load\n",
    "        device (str): Device to move the model to\n",
    "    \"\"\"\n",
    "\n",
    "    # Define as global so that changes made within the function are also applied outside of it\n",
    "    global diffusion_model\n",
    "\n",
    "    diffusion_model = DiffusionPipeline.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name\n",
    "    )\n",
    "    diffusion_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd69db8008b44d8eb1d449afb941975c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('anton-l/ddpm-butterflies-128', 'anton-l/ddp…"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive(\n",
    "    load_model,\n",
    "    {\"manual\": True},\n",
    "    model_name=[\n",
    "        \"anton-l/ddpm-butterflies-128\",\n",
    "        \"anton-l/ddpm-ema-pokemon-64\",\n",
    "        \"google/ddpm-ema-church-256\",\n",
    "        \"google/ddpm-celebahq-256\",\n",
    "        \"WiNE-iNEFF/Minecraft-Skin-Diffusion-V2\",\n",
    "    ],\n",
    "    device=fixed(DEVICE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f279c1a94e4ae094084806b01b975a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('anton-l/ddpm-butterflies-128', 'anton-l/ddp…"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive(\n",
    "    load_model,\n",
    "    {\"manual\": True},\n",
    "    model_name=[\n",
    "        \"anton-l/ddpm-butterflies-128\",\n",
    "        \"anton-l/ddpm-ema-pokemon-64\",\n",
    "        \"google/ddpm-ema-church-256\",\n",
    "        \"google/ddpm-celebahq-256\",\n",
    "        \"WiNE-iNEFF/Minecraft-Skin-Diffusion-V2\",\n",
    "    ],\n",
    "    device=fixed(DEVICE),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167ec11e033e435c8f4843bb89239428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='', description='Prompt:', placeholder='Enter your prompt...'), IntSlider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_images(prompt, num_images, steps, scheduler):\n",
    "    images = generate_images(prompt, num_images, scheduler, steps)\n",
    "    for idx, img in enumerate(images):\n",
    "        display(img)\n",
    "        img.save(f\"generated_image_{idx+1}.png\")\n",
    "\n",
    "# Create interactive widgets\n",
    "interactive_plot = interactive(display_images,\n",
    "                               prompt=widgets.Textarea(value='', placeholder='Enter your prompt...', description='Prompt:'),\n",
    "                               num_images=widgets.IntSlider(value=1, min=1, max=10, step=1, description='Num Images:'),\n",
    "                               steps=widgets.IntSlider(value=50, min=1, max=100, step=1, description='Inference Steps:'),\n",
    "                               scheduler=widgets.Dropdown(options=[\"DDIM\", \"PLMS\", \"Euler\", \"Euler a\", \"LMS\", \"Heun\", \"DPM2\", \"DPM2 a\", \"DPM++\", \"DPM++ a\"], value='DDIM', description='Scheduler:'))\n",
    "\n",
    "# Display the interactive widgets\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and display images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
